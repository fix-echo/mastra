# PDF è½¬é—®é¢˜ç”Ÿæˆå™¨

ä¸€ä¸ª Mastra æ¨¡æ¿ï¼Œæ¼”ç¤ºäº†**å¦‚ä½•é˜²æ­¢tokené™åˆ¶**ï¼Œé€šè¿‡ä»å¤§å‹æ•°æ®é›†ç”Ÿæˆ AI æ‘˜è¦ï¼Œç„¶åå°†æ‘˜è¦ä½œä¸ºå·¥å…·è°ƒç”¨çš„è¾“å‡ºè¿›è¡Œä¼ é€’ã€‚

> **ğŸ¯ æ ¸å¿ƒå­¦ä¹ ç‚¹**ï¼šæ­¤æ¨¡æ¿å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¤§ä¸Šä¸‹æ–‡çª—å£æ¨¡å‹ï¼ˆOpenAI GPT-4.1 Miniï¼‰ä½œä¸º"æ‘˜è¦å±‚"ï¼Œå°†å¤§å‹æ–‡æ¡£å‹ç¼©æˆé‡ç‚¹æ‘˜è¦ï¼Œå®ç°æ— tokené™åˆ¶çš„é«˜æ•ˆä¸‹æ¸¸å¤„ç†ã€‚

## æ¦‚è¿°

æ­¤æ¨¡æ¿å±•ç¤ºäº†ä¸€ç§ä¸å¤§å‹æ–‡æ¡£å’ŒLLMåä½œçš„å…³é”®æ¶æ„æ¨¡å¼ï¼š

**ğŸš¨ é—®é¢˜æ‰€åœ¨**ï¼šå¤§å‹ PDF å¯èƒ½åŒ…å« 50,000+ ä¸ª tokensï¼Œè¿™ä¼šä½¿ä¸Šä¸‹æ–‡çª—å£ä¸å ªé‡è´Ÿï¼Œå¹¶èŠ±è´¹æ•°åƒä¸ª token æ¥å¤„ç†ã€‚

**âœ… è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å…·æœ‰å¤§ä¸Šä¸‹æ–‡çª—å£çš„æ¨¡å‹ï¼ˆOpenAI GPT-4.1 Miniï¼‰æ¥ç”Ÿæˆé‡ç‚¹æ‘˜è¦ï¼Œç„¶åä½¿ç”¨è¿™äº›æ‘˜è¦è¿›è¡Œä¸‹æ¸¸å¤„ç†ã€‚

### å·¥ä½œæµç¨‹

1. **è¾“å…¥**: PDF URL
2. **ä¸‹è½½å’Œæ‘˜è¦**: è·å– PDFï¼Œæå–æ–‡æœ¬ï¼Œç„¶åä½¿ç”¨ OpenAI GPT-4.1 Mini ç”Ÿæˆ AI æ‘˜è¦
3. **ç”Ÿæˆé—®é¢˜**: ä»æ‘˜è¦ï¼ˆè€Œéå…¨æ–‡ï¼‰åˆ›å»ºæœ‰é’ˆå¯¹æ€§çš„é—®é¢˜

### æ ¸å¿ƒä¼˜åŠ¿

- **ğŸ“‰ Token å‡å°‘**: 80-95% çš„ token ç”¨é‡é™ä½
- **ğŸ¯ æ›´é«˜è´¨é‡**: æ¥è‡ªå…³é”®æ´å¯Ÿçš„æ›´æœ‰é’ˆå¯¹æ€§çš„é—®é¢˜
- **ğŸ’° æˆæœ¬èŠ‚çœ**: æ˜¾è‘—é™ä½å¤„ç†æˆæœ¬
- **âš¡ æ›´å¿«å¤„ç†**: æ‘˜è¦å¤„ç†é€Ÿåº¦è¿œå¿«äºå…¨æ–‡å¤„ç†

## å…ˆå†³æ¡ä»¶

- Node.js 20.9.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- OpenAI API å¯†é’¥ï¼ˆç”¨äºæ‘˜è¦å’Œé—®é¢˜ç”Ÿæˆï¼‰

## è®¾ç½®

1. **å…‹éš†å¹¶å®‰è£…ä¾èµ–é¡¹ï¼š**

   ```bash
   git clone <repository-url>
   cd template-pdf-questions
   pnpm install
   ```

2. **è®¾ç½®ç¯å¢ƒå˜é‡ï¼š**

   ```bash
   cp .env.example .env
   # ç¼–è¾‘ .env æ–‡ä»¶å¹¶æ·»åŠ æ‚¨çš„ API å¯†é’¥
   ```

   ```env
   OPENAI_API_KEY="your-openai-api-key-here"
   ```

3. **è¿è¡Œç¤ºä¾‹ï¼š**

   ```bash
   npx tsx example.ts
   ```

## ğŸ—ï¸ æ¶æ„æ¨¡å¼ï¼šToken é™åˆ¶ä¿æŠ¤

æ­¤æ¨¡æ¿æ¼”ç¤ºäº†ä¸€ç§åœ¨ LLM åº”ç”¨ä¸­å¤„ç†å¤§å‹æ•°æ®é›†çš„å…³é”®æ¨¡å¼ï¼š

### æŒ‘æˆ˜æ‰€åœ¨

åœ¨å¤„ç†å¤§å‹æ–‡æ¡£ï¼ˆPDFã€æŠ¥å‘Šã€è½¬å½•æœ¬ï¼‰æ—¶ï¼Œæ‚¨ç»å¸¸ä¼šé‡åˆ°ï¼š

- **Token é™åˆ¶**: æ–‡æ¡£å¯èƒ½è¶…å‡ºä¸Šä¸‹æ–‡çª—å£
- **é«˜æˆæœ¬**: é‡å¤å¤„ç† 50,000+ ä¸ª token éå¸¸æ˜‚è´µ
- **è´¨é‡ä¸‹é™**: LLM åœ¨å¤„ç†æé•¿è¾“å…¥æ—¶æ€§èƒ½å˜å·®
- **å¤„ç†ç¼“æ…¢**: å¤§å‹è¾“å…¥éœ€è¦æ›´é•¿çš„å¤„ç†æ—¶é—´

### è§£å†³æ–¹æ¡ˆï¼šæ‘˜è¦å±‚

ä¸è¦åœ¨æ‚¨çš„æµæ°´çº¿ä¸­ä¼ é€’åŸå§‹æ•°æ®ï¼š

1. **ä½¿ç”¨å¤§ä¸Šä¸‹æ–‡çª—å£æ¨¡å‹**ï¼ˆOpenAI GPT-4.1 Miniï¼‰æ¶ˆåŒ–å®Œæ•´å†…å®¹
2. **ç”Ÿæˆé‡ç‚¹æ‘˜è¦**ï¼Œæ•è·å…³é”®ä¿¡æ¯
3. **å°†æ‘˜è¦ä¼ é€’ç»™ä¸‹æ¸¸å¤„ç†**ï¼Œè€Œä¸æ˜¯åŸå§‹æ•°æ®

### Implementation Details

```typescript
// âŒ BAD: Pass full text through pipeline
const questions = await generateQuestions(fullPdfText); // 50,000 tokens!

// âœ… GOOD: Summarize first, then process
const summary = await summarizeWithGPT41Mini(fullPdfText); // 2,000 tokens
const questions = await generateQuestions(summary); // Much better!
```

### When to Use This Pattern

- **Large documents**: PDFs, reports, transcripts
- **Batch processing**: Multiple documents
- **Cost optimization**: Reduce token usage
- **Quality improvement**: More focused processing
- **Chain operations**: Multiple LLM calls on same data

## Usage

### Using the Workflow

```typescript
import { mastra } from './src/mastra/index';

const run = await mastra.getWorkflow('pdfToQuestionsWorkflow').createRunAsync();

// Using a PDF URL
const result = await run.start({
  inputData: {
    pdfUrl: 'https://example.com/document.pdf',
  },
});

console.log(result.result.questions);
```

### Using the PDF Questions Agent

```typescript
import { mastra } from './src/mastra/index';

const agent = mastra.getAgent('pdfQuestionsAgent');

// The agent can handle the full process with natural language
const response = await agent.stream([
  {
    role: 'user',
    content: 'Please download this PDF and generate questions from it: https://example.com/document.pdf',
  },
]);

for await (const chunk of response.textStream) {
  console.log(chunk);
}
```

### Using Individual Tools

```typescript
import { mastra } from './src/mastra/index';
import { pdfFetcherTool } from './src/mastra/tools/download-pdf-tool';
import { generateQuestionsFromTextTool } from './src/mastra/tools/generate-questions-from-text-tool';

// Step 1: Download PDF and generate summary
const pdfResult = await pdfFetcherTool.execute({
  context: { pdfUrl: 'https://example.com/document.pdf' },
  mastra,
  runtimeContext: new RuntimeContext(),
});

console.log(`Downloaded ${pdfResult.fileSize} bytes from ${pdfResult.pagesCount} pages`);
console.log(`Generated ${pdfResult.summary.length} character summary`);

// Step 2: Generate questions from summary
const questionsResult = await generateQuestionsFromTextTool.execute({
  context: {
    extractedText: pdfResult.summary,
    maxQuestions: 10,
  },
  mastra,
  runtimeContext: new RuntimeContext(),
});

console.log(questionsResult.questions);
```

### Expected Output

```javascript
{
  status: 'success',
  result: {
    questions: [
      "What is the main objective of the research presented in this paper?",
      "Which methodology was used to collect the data?",
      "What are the key findings of the study?",
      // ... more questions
    ],
    success: true
  }
}
```

## Architecture

### Components

- **`pdfToQuestionsWorkflow`**: Main workflow orchestrating the process
- **`textQuestionAgent`**: Mastra agent specialized in generating educational questions
- **`pdfQuestionAgent`**: Complete agent that can handle the full PDF to questions pipeline

### Tools

- **`pdfFetcherTool`**: Downloads PDF files from URLs, extracts text, and generates AI summaries
- **`generateQuestionsFromTextTool`**: Generates comprehensive questions from summarized content

### Workflow Steps

1. **`download-and-summarize-pdf`**: Downloads PDF from provided URL and generates AI summary
2. **`generate-questions-from-summary`**: Creates comprehensive questions from the AI summary

## Features

- âœ… **Token Limit Protection**: Demonstrates how to handle large datasets without hitting context limits
- âœ… **80-95% Token Reduction**: AI summarization drastically reduces processing costs
- âœ… **Large Context Window**: Uses OpenAI GPT-4.1 Mini to handle large documents efficiently
- âœ… **Zero System Dependencies**: Pure JavaScript solution
- âœ… **Single API Setup**: OpenAI for both summarization and question generation
- âœ… **Fast Text Extraction**: Direct PDF parsing (no OCR needed for text-based PDFs)
- âœ… **Educational Focus**: Generates focused learning questions from key insights
- âœ… **Multiple Interfaces**: Workflow, Agent, and individual tools available

## How It Works

### Text Extraction Strategy

This template uses a **pure JavaScript approach** that works for most PDFs:

1. **Text-based PDFs** (90% of cases): Direct text extraction using `pdf2json`
   - âš¡ Fast and reliable
   - ğŸ”§ No system dependencies
   - âœ… Works out of the box

2. **Scanned PDFs**: Would require OCR, but most PDFs today contain embedded text

### Why This Approach?

- **Simplicity**: No GraphicsMagick, ImageMagick, or other system tools needed
- **Speed**: Direct text extraction is much faster than OCR
- **Reliability**: Works consistently across different environments
- **Educational**: Easy for developers to understand and modify
- **Single Path**: One clear workflow with no complex branching

## Configuration

### Environment Variables

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### Customization

You can customize the question generation by modifying the `textQuestionAgent`:

```typescript
export const textQuestionAgent = new Agent({
  name: 'Generate questions from text agent',
  instructions: `
    You are an expert educational content creator...
    // Customize instructions here
  `,
  model: openai('gpt-4o'),
});
```

## Development

### Project Structure

```text
src/mastra/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ pdf-question-agent.ts       # PDF processing and question generation agent
â”‚   â””â”€â”€ text-question-agent.ts      # Text to questions generation agent
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ download-pdf-tool.ts         # PDF download tool
â”‚   â”œâ”€â”€ extract-text-from-pdf-tool.ts # PDF text extraction tool
â”‚   â””â”€â”€ generate-questions-from-text-tool.ts # Question generation tool
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ generate-questions-from-pdf-workflow.ts # Main workflow
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ util.ts                      # Utility functions including PDF text extraction
â””â”€â”€ index.ts                         # Mastra configuration
```

### Testing

```bash
# Run with a test PDF
export OPENAI_API_KEY="your-api-key"
npx tsx example.ts
```

## Common Issues

### "OPENAI_API_KEY is not set"

- Make sure you've set the environment variable
- Check that your API key is valid and has sufficient credits

### "Failed to download PDF"

- Verify the PDF URL is accessible and publicly available
- Check network connectivity
- Ensure the URL points to a valid PDF file
- Some servers may require authentication or have restrictions

### "No text could be extracted"

- The PDF might be password-protected
- Very large PDFs might take longer to process
- Scanned PDFs without embedded text won't work (rare with modern PDFs)

### "Context length exceeded" or Token Limit Errors

- **Solution**: Use a smaller PDF file (under ~5-10 pages)
- **Automatic Truncation**: The tool automatically uses only the first 4000 characters for very large documents
- **Helpful Errors**: Clear messages guide you to use smaller PDFs when needed

## What Makes This Template Special

### ğŸ¯ **True Simplicity**

- Single dependency for PDF processing (`pdf2json`)
- No system tools or complex setup required
- Works immediately after `pnpm install`
- Multiple usage patterns (workflow, agent, tools)

### âš¡ **Performance**

- Direct text extraction (no image conversion)
- Much faster than OCR-based approaches
- Handles reasonably-sized documents efficiently

### ğŸ”§ **Developer-Friendly**

- Pure JavaScript/TypeScript
- Easy to understand and modify
- Clear separation of concerns
- Simple error handling with helpful messages

### ğŸ“š **Educational Value**

- Generates multiple question types
- Covers different comprehension levels
- Perfect for creating study materials

## ğŸš€ Broader Applications

This token limit protection pattern can be applied to many other scenarios:

### Document Processing

- **Legal documents**: Summarize contracts before analysis
- **Research papers**: Extract key findings before comparison
- **Technical manuals**: Create focused summaries for specific topics

### Content Analysis

- **Social media**: Summarize large thread conversations
- **Customer feedback**: Compress reviews before sentiment analysis
- **Meeting transcripts**: Extract action items and decisions

### Data Processing

- **Log analysis**: Summarize error patterns before classification
- **Survey responses**: Compress feedback before theme extraction
- **Code reviews**: Summarize changes before generating reports

### Implementation Tips

- Use **OpenAI GPT-4.1 Mini** for initial summarization (large context window)
- Pass **summaries** to downstream tools, not raw data
- **Chain summaries** for multi-step processing
- **Preserve metadata** (file size, page count) for context

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request
